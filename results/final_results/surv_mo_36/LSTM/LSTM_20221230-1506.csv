epoch,acc,bal_acc,auc,prec,rec,spec,f1,loss,ppv,npv,tp,fp,tn,fn
0,0.84034663438797,0.82633376121521,0.9094775319099426,0.8866891860961914,0.8697505593299866,0.7829170227050781,0.8781381845474243,0.273334264755249,0.8866892000643811,0.754756242568371,5509.0,704.0,2539.0,825.0

Run Arguments:
cuda: True
gpu: 0
cuda_block: False
epochs: 100
seed: 3435
patience: 5
monitor_metric: bal_acc
log_every: 10
imbalance_fix: loss_weight
data_dir: C:\Users\jjnunez\PycharmProjects\scar_nlp_data\data
results_dir: C:\Users\jjnunez\PycharmProjects\scar_nlp_survival\results
data_version: ppv4
target: surv_mo_36
table: survival_dif_lengths
table_extra: 36
dataset: SCAR
debug: False
eval_only: True
model_file: C:\Users\jjnunez\PycharmProjects\scar_nlp_survival\results\paper_submission\surv_mo_36\LSTM\LSTM_20220929-1840.pt
bidirectional: True
num_layers: 1
hidden_dim: 512
mode: rand
words_dim: 300
embed_dim: 300
weight_decay: 0
dropout: 0.2
lr: 5e-05
batch_size: 16
embed_droprate: 0.2
wdrop: 0.3
pretrained_dir: C:\Users\jjnunez\PycharmProjects\hedwig-data\embeddings\word2vec
pretrained_file: GoogleNews-vectors-negative300.txt
results_path: results\reg_lstm
device: cuda:0
target_classes: 1
vocab_size: 21689
run_name: LSTM_20221230-1506
results_dir_target: C:\Users\jjnunez\PycharmProjects\scar_nlp_survival\results\surv_mo_36
results_dir_model: C:\Users\jjnunez\PycharmProjects\scar_nlp_survival\results\surv_mo_36\LSTM
