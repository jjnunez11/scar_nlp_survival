{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe216e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, os.path.abspath('../'))\n",
    "\n",
    "import captum\n",
    "\n",
    "import torch\n",
    "import torchtext\n",
    "import torchtext.data\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torchtext.vocab import Vocab\n",
    "\n",
    "from captum.attr import LayerIntegratedGradients, TokenReferenceBase, visualization\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "\n",
    "from models.lstm.model import LSTM\n",
    "from datasets.scar import SCAR\n",
    "\n",
    "MAYBE TRY THIS INSTEAD: https://github.com/Jarvx/text-classification-pytorch/blob/master/model.py\n",
    "\n",
    "\n",
    "tokenizer = get_tokenizer('basic_english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b2ee78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb4f91c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.embed num_embeddings is: 21696 while embedding_dim is 300\n",
      "Applying weight drop of 0.3 to weight_hh_l0\n",
      "LSTM(\n",
      "  (embed): Embedding(21696, 300)\n",
      "  (lstm): WeightDrop(\n",
      "    (module): LSTM(300, 512, batch_first=True, dropout=0.2, bidirectional=True)\n",
      "  )\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (fc1): Linear(in_features=1024, out_features=1, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jjnunez\\.conda\\envs\\scar_nlp\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:62: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    }
   ],
   "source": [
    "#Survival 60 mo\n",
    "ckpt_name = \"LSTM_20220909-2323\"\n",
    "ckpt_path = os.path.join(r\"C:\\Users\\jjnunez\\PycharmProjects\\scar_nlp_survival\\results\\surv_mo_60\\LSTM\", ckpt_name + \".pt\")\n",
    "\n",
    "\n",
    "checkpoint = torch.load(ckpt_path)\n",
    "\n",
    "model = LSTM(config=checkpoint['config'])\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "model.eval()\n",
    "model = model.to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9dae296",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_with_sigmoid(input):\n",
    "    return torch.sigmoid(model(input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0fd5d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEXT = torchtext.legacy.data.Field(lower=True, tokenize=tokenizer)\n",
    "# Label = torchtext.legacy.data.LabelField(dtype = torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6651461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = IMDB(split='train')\n",
    "#test = IMDB(split='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a0c905e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchtext import vocab\n",
    "\n",
    "#loaded_vectors = vocab.GloVe(name='6B', dim=100)\n",
    "\n",
    "#TEXT.build_vocab(train, vectors=loaded_vectors, max_size=len(loaded_vectors.stoi))\n",
    "    \n",
    "#TEXT.vocab.set_vectors(stoi=loaded_vectors.stoi, vectors=loaded_vectors.vectors, dim=loaded_vectors.dim)\n",
    "#Label.build_vocab(train, vectors=loaded_vectors, max_size=len(loaded_vectors.stoi))\n",
    "\n",
    "#print('Vocabulary Size: ', len(TEXT.vocab))\n",
    "#print('Vocabulary Size: ', len(Label.vocab))\n",
    "#print(train)\n",
    "#print(Label.vocab.itos)\n",
    "config = checkpoint['config']\n",
    "scar = SCAR(config.batch_size, config.data_dir, config.target)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a0a3d1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21689\n"
     ]
    }
   ],
   "source": [
    "vocab = scar.vocab\n",
    "itos = vocab.get_itos()\n",
    "print(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d498292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "909\n",
      "<captum.attr._core.layer.layer_integrated_gradients.LayerIntegratedGradients object at 0x000000F5909CA670>\n"
     ]
    }
   ],
   "source": [
    "# PAD_IND = TEXT.vocab.stoi[TEXT.pad_token]\n",
    "print(vocab['doctor'])\n",
    "PAD_IND = vocab['<PAD>']\n",
    "token_reference = TokenReferenceBase(reference_token_idx=PAD_IND)\n",
    "lig = LayerIntegratedGradients(model, model.embed)\n",
    "print(lig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a4e79935",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accumalate couple samples in this array for visualization purposes\n",
    "vis_data_records_ig = []\n",
    "lig = LayerIntegratedGradients(model, model.embed)\n",
    "def interpret_sentence(model, sentence, min_len = 50, label = 0):\n",
    "    text = [tok for tok in tokenizer(sentence.lower())]\n",
    "    if len(text) < min_len:\n",
    "        text += ['<PAD>'] * (min_len - len(text))\n",
    "    indexed = [vocab[t] for t in text]\n",
    "\n",
    "    model.zero_grad()\n",
    "   \n",
    "    input_indices = torch.tensor(indexed, device=device)\n",
    "    input_indices = input_indices.unsqueeze(0)\n",
    "    \n",
    "    # input_indices dim: [sequence_length]\n",
    "    seq_length = min_len\n",
    "\n",
    "    # predict\n",
    "    pred = forward_with_sigmoid(input_indices).item()\n",
    "    pred_ind = round(pred)\n",
    "    \n",
    "    print(f'here is: {pred}')\n",
    "\n",
    "    # generate reference indices for each sample\n",
    "    reference_indices = token_reference.generate_reference(seq_length, device=device).unsqueeze(0)\n",
    "    \n",
    "    print(f'Here is the input_indices.size {input_indices.size()}')\n",
    "    print(f'Here is the reference_indices.size {reference_indices.size()}')\n",
    "    \n",
    "    print(f'Here is the input_indices {input_indices}')\n",
    "    print(f'Here is the reference_indices {reference_indices}')\n",
    "    \n",
    "    # compute attributions and approximation delta using layer integrated gradients\n",
    "    attributions_ig, delta = lig.attribute(input_indices, reference_indices, \\\n",
    "                                           n_steps=500, return_convergence_delta=True)\n",
    "    # Replace Label with Text below\n",
    "    print(itos[pred_ind])\n",
    "    print('pred: ', itos[pred_ind], '(', '%.2f'%pred, ')', ', delta: ', abs(delta))\n",
    "\n",
    "    add_attributions_to_visualizer(attributions_ig, text, pred, pred_ind, label, delta, vis_data_records_ig)\n",
    "    \n",
    "def add_attributions_to_visualizer(attributions, text, pred, pred_ind, label, delta, vis_data_records):\n",
    "    attributions = attributions.sum(dim=2).squeeze(0)\n",
    "    attributions = attributions / torch.norm(attributions)\n",
    "    attributions = attributions.cpu().detach().numpy()\n",
    "\n",
    "    # storing couple samples in an array for visualization purposes\n",
    "    vis_data_records.append(visualization.VisualizationDataRecord(\n",
    "                            attributions,\n",
    "                            pred,\n",
    "                            itos[pred_ind],\n",
    "                            itos[label],\n",
    "                            itos[1],\n",
    "                            attributions.sum(),\n",
    "                            text,\n",
    "                            delta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22b3a7ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jjnunez\\.conda\\envs\\scar_nlp\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:679: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters(). (Triggered internally at  ..\\aten\\src\\ATen\\native\\cudnn\\RNN.cpp:924.)\n",
      "  result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here is: 0.7366713285446167\n",
      "Here is the input_indices.size torch.Size([1, 50])\n",
      "Here is the reference_indices.size torch.Size([1, 50])\n",
      "Here is the input_indices tensor([[  106,     4,  3768,    11,     9,  1168,    61,    76,   227,    14,\n",
      "           138,   161,    60,   127,    41,     4,    13,   231,   608,     7,\n",
      "            75,    27,   203,     4,    13,   644,   134, 11520,     4,    13,\n",
      "            18,     9,  1378,     8,    85,     4,     3,     3,     3,     3,\n",
      "             3,     3,     3,     3,     3,     3,     3,     3,     3,     3]],\n",
      "       device='cuda:0')\n",
      "Here is the reference_indices tensor([[3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "         3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3,\n",
      "         3, 3]], device='cuda:0')\n",
      "here is the single layer: Embedding(21696, 300)\n",
      "line 294 if FALSE\n",
      "entered hook_wrapper\n",
      "entered registered forward_hooks\n",
      "handle: <torch.utils.hooks.RemovableHandle object at 0x000000F59733F370>\n",
      "about to run_forward\n",
      "Entered run_forward\n",
      "in forward_run, len(forward_func_args) != 0\n",
      "entering forward_func: LSTM(\n",
      "  (embed): Embedding(21696, 300)\n",
      "  (lstm): WeightDrop(\n",
      "    (module): LSTM(300, 512, batch_first=True, dropout=0.2, bidirectional=True)\n",
      "  )\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (fc1): Linear(in_features=1024, out_features=1, bias=True)\n",
      ")\n",
      "exiting forward_func\n",
      "finished run_forward\n",
      "about to check length of saved_layer\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "Forward hook did not obtain any outputs for given layer",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\3/ipykernel_3436/2630938720.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Ms. Jones is a 64 year old woman with metastatic stage 4 lung cancer. She lives alone and does not work. She feels very sad. She has a lot of pain.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# text = \"Ms. Jones is a 64 year old woman with metastatic stage 4 lung cancer.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0minterpret_sentence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\3/ipykernel_3436/144902055.py\u001b[0m in \u001b[0;36minterpret_sentence\u001b[1;34m(model, sentence, min_len, label)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[1;31m# compute attributions and approximation delta using layer integrated gradients\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m     attributions_ig, delta = lig.attribute(input_indices, reference_indices, \\\n\u001b[0m\u001b[0;32m     35\u001b[0m                                            n_steps=500, return_convergence_delta=True)\n\u001b[0;32m     36\u001b[0m     \u001b[1;31m# Replace Label with Text below\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\scar_nlp\\lib\\site-packages\\captum\\log\\__init__.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     33\u001b[0m             \u001b[1;33m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m             \u001b[1;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\scar_nlp\\lib\\site-packages\\captum\\attr\\_core\\layer\\layer_integrated_gradients.py\u001b[0m in \u001b[0;36mattribute\u001b[1;34m(self, inputs, baselines, target, additional_forward_args, n_steps, method, internal_batch_size, return_convergence_delta, attribute_to_layer_input)\u001b[0m\n\u001b[0;32m    363\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_ids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward_func\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"device_ids\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 365\u001b[1;33m         inputs_layer = _forward_layer_eval(\n\u001b[0m\u001b[0;32m    366\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward_func\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    367\u001b[0m             \u001b[0minps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\scar_nlp\\lib\\site-packages\\captum\\_utils\\gradient.py\u001b[0m in \u001b[0;36m_forward_layer_eval\u001b[1;34m(forward_fn, inputs, layer, additional_forward_args, device_ids, attribute_to_layer_input, grad_enabled)\u001b[0m\n\u001b[0;32m    179\u001b[0m     \u001b[0mgrad_enabled\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    180\u001b[0m ) -> Union[Tuple[Tensor, ...], List[Tuple[Tensor, ...]]]:\n\u001b[1;32m--> 181\u001b[1;33m     return _forward_layer_eval_with_neuron_grads(\n\u001b[0m\u001b[0;32m    182\u001b[0m         \u001b[0mforward_fn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m         \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\scar_nlp\\lib\\site-packages\\captum\\_utils\\gradient.py\u001b[0m in \u001b[0;36m_forward_layer_eval_with_neuron_grads\u001b[1;34m(forward_fn, inputs, layer, additional_forward_args, gradient_neuron_selector, grad_enabled, device_ids, attribute_to_layer_input)\u001b[0m\n\u001b[0;32m    454\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    455\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad_enabled\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 456\u001b[1;33m         saved_layer = _forward_layer_distributed_eval(\n\u001b[0m\u001b[0;32m    457\u001b[0m             \u001b[0mforward_fn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    458\u001b[0m             \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\scar_nlp\\lib\\site-packages\\captum\\_utils\\gradient.py\u001b[0m in \u001b[0;36m_forward_layer_distributed_eval\u001b[1;34m(forward_fn, inputs, layer, target_ind, additional_forward_args, attribute_to_layer_input, forward_hook_with_return, require_layer_grads)\u001b[0m\n\u001b[0;32m    313\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"about to check length of saved_layer\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    314\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msaved_layer\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 315\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Forward hook did not obtain any outputs for given layer\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    316\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"saved_layer length checked and passed!\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: Forward hook did not obtain any outputs for given layer"
     ]
    }
   ],
   "source": [
    "text = \"Ms. Jones is a 64 year old woman with metastatic stage 4 lung cancer. She lives alone and does not work. She feels very sad. She has a lot of pain.\"\n",
    "# text = \"Ms. Jones is a 64 year old woman with metastatic stage 4 lung cancer.\"\n",
    "interpret_sentence(model, text, label=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed77d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Visualize attributions based on Integrated Gradients')\n",
    "_ = visualization.visualize_text(vis_data_records_ig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec71c84e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
